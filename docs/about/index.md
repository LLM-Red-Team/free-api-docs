

# LLM Red Team



如果您看到了这个组织，请允许我为您介绍它：

LLM Red Team 意为 LLM大模型红队，大模型应用发展速度超乎了所有人的预料，在这样的表象下是日益严重的安全风险。

本组织成立的愿景是通过各厂商大模型应用中已公开的信息挖掘潜在的安全问题并公开一些技术细节，如果影响到您应用的正常运营请联系组织负责人，我们会及时下线相关仓库。

**所有内容仅供研究禁止套壳对外服务对官方造成服务压力！！**

以下是我们目前已公开的仓库：

Moonshot AI (Kimi.ai) 接口转API [kimi-free-api](https://github.com/LLM-Red-Team/kimi-free-api)

阶跃星辰 (跃问StepChat) 接口转API [step-free-api](https://github.com/LLM-Red-Team/step-free-api)

阿里通义 (Qwen) 接口转API [qwen-free-api](https://github.com/LLM-Red-Team/qwen-free-api)

ZhipuAI (智谱清言) 接口转API [glm-free-api](https://github.com/LLM-Red-Team/glm-free-api)

秘塔AI (metaso) 接口转API [metaso-free-api](https://github.com/LLM-Red-Team/metaso-free-api)

讯飞星火（spark）接口转API [spark-free-api](https://github.com/LLM-Red-Team/spark-free-api)

聆心智能 (Emohaa) 接口转API [emohaa-free-api](https://github.com/LLM-Red-Team/emohaa-free-api)

此外，我们提出一种可能的提高逆向成本的方案：[ban-free-api](https://github.com/LLM-Red-Team/ban-free-api)